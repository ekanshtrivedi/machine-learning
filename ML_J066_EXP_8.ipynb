{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_J066_EXP_8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3Tpr/qLzSqzESz2/P+Kum",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekanshtrivedi/machine-learning/blob/master/ML_J066_EXP_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HajU8CtVGgfy"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01HRiBR-GsC4"
      },
      "source": [
        "EXTRACTING IMAGE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWCxgQB-Gpja"
      },
      "source": [
        "!mkdir /content/IndAfrTusk_train/ \n",
        "!mkdir /content/IndAfrTusk_valid/\n",
        "!mkdir /content/IndAfrTusk_test/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO8dR19sGvRi"
      },
      "source": [
        "img_rows, img_cols = 240, 240\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "num_train = 210\n",
        "num_valid = 70\n",
        "num_test = 70"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oNIae6NGzBs"
      },
      "source": [
        "ind_ele = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02504013\")\n",
        "ind_ele_soup = BeautifulSoup(ind_ele.content, 'html.parser')\n",
        "ind_ele_str = str(ind_ele_soup)\n",
        "ind_ele_urls = ind_ele_str.split('\\r\\n')\n",
        "\n",
        "afr_ele = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02504458\")\n",
        "afr_ele_soup = BeautifulSoup(afr_ele.content, 'html.parser')\n",
        "afr_ele_str = str(afr_ele_soup)\n",
        "afr_ele_urls = afr_ele_str.split('\\r\\n')\n",
        "\n",
        "tusker = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n01871265\")\n",
        "tusker_soup = BeautifulSoup(tusker.content, 'html.parser')\n",
        "tusker_str = str(tusker_soup)\n",
        "tusker_urls = tusker_str.split('\\r\\n')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw5kdS2UG2g4"
      },
      "source": [
        "def image_from_url(link):\n",
        "\tresp = urllib.request.urlopen(link)\n",
        "\timg = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timg = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
        "\treturn img"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKlNgFmbG-K1",
        "outputId": "4295dc52-00d1-4130-f370-a081f93d2591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for progress in tqdm(range(num_train)):\n",
        "    if not ind_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = image_from_url(ind_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_train/Indian.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_train)):\n",
        "    if not afr_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = image_from_url(afr_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_train/African.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_train)):\n",
        "    if not tusker_urls[progress] == None:\n",
        "      try:\n",
        "        I = image_from_url(tusker_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_train/Tusker.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 210/210 [03:50<00:00,  1.10s/it]\n",
            "100%|██████████| 210/210 [02:43<00:00,  1.28it/s]\n",
            "100%|██████████| 210/210 [04:17<00:00,  1.23s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IalYv1UmHBRg",
        "outputId": "01ebef16-00e1-4fe1-e32a-d3e0a4ed2d6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for progress in tqdm(range(num_valid)):\n",
        "    if not ind_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = image_from_url(ind_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_valid/Indian.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_valid)):\n",
        "    if not afr_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = image_from_url(afr_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_valid/African.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_valid)):\n",
        "    if not tusker_urls[progress] == None:\n",
        "      try:\n",
        "        I = image_from_url(tusker_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_valid/Tusker.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70/70 [01:43<00:00,  1.49s/it]\n",
            "100%|██████████| 70/70 [00:25<00:00,  2.79it/s]\n",
            "100%|██████████| 70/70 [02:06<00:00,  1.80s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10oWcZbFHE_c",
        "outputId": "c7cba121-94ae-4b85-c26d-78481a185cd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for progress in tqdm(range(num_test)):\n",
        "    if not ind_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = image_from_url(ind_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_test/Indian.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_test)):\n",
        "    if not afr_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = image_from_url(afr_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_test/African.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_test)):\n",
        "    if not tusker_urls[progress] == None:\n",
        "      try:\n",
        "        I = image_from_url(tusker_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_test/Tusker.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70/70 [01:39<00:00,  1.41s/it]\n",
            "100%|██████████| 70/70 [00:24<00:00,  2.82it/s]\n",
            "100%|██████████| 70/70 [01:41<00:00,  1.45s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD9aMgYsHIXV"
      },
      "source": [
        "og_train, og_valid, og_test = '/content/IndAfrTusk_train', '/content/IndAfrTusk_valid','/content/IndAfrTusk_test'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFAB65x8HK_B"
      },
      "source": [
        "filenames = os.listdir(og_train)\n",
        "cat_train = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'Indian':\n",
        "        cat_train.append('0')\n",
        "    elif category == 'African':\n",
        "        cat_train.append('1')\n",
        "    else:\n",
        "        cat_train.append('2')\n",
        "\n",
        " \n",
        "filenames = os.listdir(og_valid)\n",
        "cat_valid = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'Indian':\n",
        "        cat_valid.append('0')\n",
        "    elif category == 'African':\n",
        "        cat_valid.append('1')\n",
        "    else:\n",
        "        cat_valid.append('2')\n",
        "\n",
        "\n",
        "filenames = os.listdir(og_test)\n",
        "cat_test = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'Indian':\n",
        "        cat_test.append('0')\n",
        "    elif category == 'African':\n",
        "        cat_test.append('1')\n",
        "    else:\n",
        "        cat_test.append('2')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b712vlyLHPCg"
      },
      "source": [
        "train = pd.DataFrame({'File':os.listdir(og_train),'Label':cat_train})\n",
        "train.to_csv('IndianAfricanTusk_train.csv',index=False)\n",
        "\n",
        "valid = pd.DataFrame({'File':os.listdir(og_valid),'Label':cat_valid})\n",
        "valid.to_csv('IndianAfricanTusk_valid.csv',index=False)\n",
        "\n",
        "test = pd.DataFrame({'File':os.listdir(og_test),'Label':cat_test})\n",
        "test.to_csv('IndianAfricanTusk_test.csv',index=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bycDgChKHUgs"
      },
      "source": [
        "IMAGE PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbcc_PGOHSH8",
        "outputId": "fe97b9f5-0430-418b-838d-ff1c926dacfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train.shape)\n",
        "print(valid.shape) \n",
        "print(test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(405, 2)\n",
            "(128, 2)\n",
            "(128, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKt-3JccHYA-"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPFChKz_HbYI"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   zoom_range=0.1,\n",
        "                                   vertical_flip=True,\n",
        "                                   horizontal_flip=True,\n",
        "                                   rotation_range=90,\n",
        "                                   shear_range=0.1,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1/255.0,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   zoom_range=0.1,\n",
        "                                   vertical_flip=True,\n",
        "                                   horizontal_flip=True,\n",
        "                                   rotation_range=90,\n",
        "                                   shear_range=0.1,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HN4Ab_WHezc",
        "outputId": "2e1b8de5-18f5-4c00-86bc-fc2369732913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_aug = train_datagen.flow_from_dataframe(dataframe=train,\n",
        "                                              directory=og_train,\n",
        "                                              x_col='File',\n",
        "                                              y_col='Label',\n",
        "                                              target_size=(img_rows, img_cols),\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=True,\n",
        "                                              seed=0,\n",
        "                                              color_mode='rgb')\n",
        "\n",
        "valid_aug = valid_datagen.flow_from_dataframe(dataframe=valid,\n",
        "                                              directory=og_valid,\n",
        "                                              x_col='File',\n",
        "                                              y_col='Label',\n",
        "                                              target_size=(img_rows, img_cols),\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=True,\n",
        "                                              seed=0,\n",
        "                                              color_mode='rgb')\n",
        "\n",
        "test_aug = test_datagen.flow_from_dataframe(dataframe=test,\n",
        "                                            directory=og_test,\n",
        "                                            x_col='File',\n",
        "                                            y_col='Label',\n",
        "                                            target_size=(img_rows, img_cols),\n",
        "                                            class_mode='categorical',\n",
        "                                            shuffle=False,\n",
        "                                            color_mode='rgb')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 405 validated image filenames belonging to 3 classes.\n",
            "Found 128 validated image filenames belonging to 3 classes.\n",
            "Found 128 validated image filenames belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt04NpYFHl0U"
      },
      "source": [
        "MODEL BUILDING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8Hi2rlqHiVv",
        "outputId": "15fc4487-9533-4a50-ab68-3bb47b89298f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(512, kernel_size=(img_rows, img_cols), padding='valid', activation='relu',input_shape=input_shape))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 1, 1, 512)         88474112  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 89,526,275\n",
            "Trainable params: 89,526,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBuvaFCoHpb7"
      },
      "source": [
        "filepath = \"weights-best.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'accuracy', verbose=1, patience=3, save_best_only=True, mode='max')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, min_delta=0.01, baseline=0.9)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=3, factor=0.1, min_lr=0.00001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCcBPG46HsVq",
        "outputId": "4e1853cb-e1b8-4d51-a8b4-3cd9ea95fccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train_aug, validation_data=valid_aug, epochs=1000, callbacks=[checkpoint,es,reduce_lr])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1429 - accuracy: 0.3457\n",
            "Epoch 00001: accuracy improved from -inf to 0.34568, saving model to weights-best.hdf5\n",
            "13/13 [==============================] - 58s 4s/step - loss: 1.1429 - accuracy: 0.3457 - val_loss: 1.1046 - val_accuracy: 0.2578\n",
            "Epoch 2/1000\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1061 - accuracy: 0.3333\n",
            "Epoch 00002: accuracy did not improve from 0.34568\n",
            "13/13 [==============================] - 57s 4s/step - loss: 1.1061 - accuracy: 0.3333 - val_loss: 1.0787 - val_accuracy: 0.4141\n",
            "Epoch 3/1000\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0957 - accuracy: 0.3877\n",
            "Epoch 00003: accuracy improved from 0.34568 to 0.38765, saving model to weights-best.hdf5\n",
            "13/13 [==============================] - 57s 4s/step - loss: 1.0957 - accuracy: 0.3877 - val_loss: 1.0904 - val_accuracy: 0.3281\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e90455160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFfXwLIHvDh",
        "outputId": "fb026d94-c001-4aea-942b-a08aafc3f720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(test_aug)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 185ms/step - loss: 1.0908 - accuracy: 0.3281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0908293724060059, 0.328125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Qci4FdHxxm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}